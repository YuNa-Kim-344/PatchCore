{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: sympy in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: numpy in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kim-yuna/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu102 (from versions: 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0+cu102\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4])\n",
      "tensor([1, 5])\n",
      "tensor([3])\n"
     ]
    }
   ],
   "source": [
    "# 사용자 정의 데이터셋 클래스\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 데이터 예제 (실제 데이터로 대체 가능)\n",
    "# 실제로는 DATA_ROOT 경로를 사용하여 데이터를 로드해야 합니다.\n",
    "# 예를 들어, 이미지 파일을 로드하는 경우 PIL이나 OpenCV를 사용합니다.\n",
    "data = [1, 2, 3, 4, 5]\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "dataset = MyDataset(data)\n",
    "\n",
    "# 데이터로더 생성\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 데이터로더 사용 예시\n",
    "for batch in data_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhLyvbEbm8s3",
    "outputId": "a68eed8e-873d-4ab2-8de4-2e4786599c4a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# DATA_ROOT = \"/content/drive/MyDrive/Colab Notebooks/Anomaly_detection/Data/MvTec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fkpVfxXOZaZ-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /Users/kim-yuna/.cache/torch/hub/v0.10.0.zip\n",
      "/Users/kim-yuna/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/kim-yuna/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /Users/kim-yuna/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n",
      "100%|████████████████████████████████████████| 132M/132M [00:22<00:00, 6.02MB/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load wide-ResNet\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch/vision:v0.10.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwide_resnet50_2\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:911\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mcuda(device))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:911\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mcuda(device))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Load wide-ResNet\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet50_2', pretrained=True)\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKbN_sX7ZaZ_",
    "outputId": "70e243e7-2324-458e-b553-1b3f38f83e17"
   },
   "outputs": [],
   "source": [
    "# Set hooks for outputs\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        if name not in activation:\n",
    "            activation[name] = torch.tensor([])\n",
    "        activation[name] = torch.cat((activation[name], output.detach().cpu()))\n",
    "    return hook\n",
    "\n",
    "\n",
    "model.layer2.register_forward_hook(get_activation('layer2'))\n",
    "model.layer3.register_forward_hook(get_activation('layer3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmMaZPAnZaaA"
   },
   "source": [
    "### Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSl-JEIHZaaD"
   },
   "outputs": [],
   "source": [
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.data = image_paths\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.data[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "transforms.Resize(256),\n",
    "transforms.CenterCrop(224),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# MVTec metal_nut class\n",
    "train_paths = list(sorted(Path(DATA_ROOT + \"/metal_nut/train/good\").glob(\"./*.png\")))\n",
    "test_paths = list(sorted(Path(DATA_ROOT + \"/metal_nut/test/color\").glob(\"./*.png\")))[:3] + list(sorted(Path(DATA_ROOT + \"/metal_nut/test/good\").glob(\"./*.png\")))[:2]\n",
    "\n",
    "train_outputs = OrderedDict([('layer2', []), ('layer3', [])])\n",
    "test_outputs = OrderedDict([ ('layer2', []), ('layer3', [])])\n",
    "\n",
    "trainset = BrainDataset(train_paths, transform=transform)\n",
    "train_dataloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = BrainDataset(test_paths, transform=transform)\n",
    "test_dataloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVYU2Y-7ZaaJ"
   },
   "source": [
    "### Fetures of normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gIHzfTgZaaK",
    "outputId": "cda6dd47-d30a-4bb5-e0f8-96e7da9f776d"
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "with torch.no_grad():\n",
    "  for x in tqdm(train_dataloader, position =0):\n",
    "      model(x.cuda())\n",
    "\n",
    "for layer in ['layer2', 'layer3']:\n",
    "    train_outputs[layer] = activation[layer]\n",
    "\n",
    "for layer in ['layer2', 'layer3']:\n",
    "    print(train_outputs[layer].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ6isshsZaaL"
   },
   "source": [
    "### Features of abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZC4xiJ9dZaaM",
    "outputId": "12848e36-d226-4a08-89c6-708375b0dcf0"
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "with torch.no_grad():\n",
    "  for x in tqdm(test_dataloader, position =0):\n",
    "      model(x.cuda())\n",
    "\n",
    "for layer in ['layer2', 'layer3']:\n",
    "    test_outputs[layer] = activation[layer]\n",
    "\n",
    "for layer in ['layer2', 'layer3']:\n",
    "    print(test_outputs[layer].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzObmReAuK1C"
   },
   "source": [
    "### Understand how unfold works with examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "id": "oUnxWTe_iN8q",
    "outputId": "4bfc4f79-6c40-4634-b8cc-3f23df100e11"
   },
   "outputs": [],
   "source": [
    "x = torch.from_numpy((100*np.random.random((1, 3, 3, 3))).astype(np.uint8))\n",
    "\n",
    "plt.imshow(x.squeeze(0).permute(1, 2, 0))\n",
    "plt.show()\n",
    "kernel_size = 3\n",
    "x = F.pad(x, (0, 0, kernel_size//2, kernel_size//2))\n",
    "print(\"dim 2 padded  \", x.size())\n",
    "x = x.unfold(2, kernel_size, 1)\n",
    "print(\"dim 2 unfolded\", x.size())\n",
    "x = F.pad(x, (0, 0, kernel_size//2, kernel_size//2, 0, 0))\n",
    "print(\"dim 3 padded  \", x.size())\n",
    "x = x.unfold(3, kernel_size, 1)\n",
    "print(\"dim 3 unfolded\", x.size())\n",
    "\n",
    "x = torch.squeeze(x.permute([0, 2, 3, 1, 4, 5]))\n",
    "\n",
    "plt.imshow(x.permute(2, 0, 3, 1, 4).reshape(3, 3*kernel_size, 3*kernel_size).permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BRTw5enKMtja",
    "outputId": "afdd4a94-6f28-4388-b1ac-6274789ad4bf"
   },
   "outputs": [],
   "source": [
    "x = transforms.ToTensor()(Image.open(\"IMG_2964.jpeg\")).unsqueeze(0)\n",
    "print(\"og\", x.size()) # [1, 3, 830, 830]\n",
    "\n",
    "# Assuming kernel is odd, pad kernel//2.\n",
    "kernel_size = 128\n",
    "x = F.pad(x, (0, 0, kernel_size//2, kernel_size//2))\n",
    "print(\"dim 2 padded  \", x.size())\n",
    "x = x.unfold(2, kernel_size, step=40)\n",
    "print(\"dim 2 unfolded\", x.size())\n",
    "x = F.pad(x, (0, 0, kernel_size//2, kernel_size//2, 0, 0))\n",
    "print(\"dim 3 padded  \", x.size())\n",
    "x = x.unfold(3, kernel_size, step=30)\n",
    "print(\"dim 3 unfolded\", x.size())\n",
    "\n",
    "x = torch.squeeze(x.permute([0, 2, 3, 1, 4, 5]))\n",
    "print(\"move channel and squeeze\", x.size())\n",
    "print()\n",
    "print(\"example patch\")\n",
    "plt.imshow(x[0, 0].permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "print(\"patched image\")\n",
    "plt.imshow(x.permute(2, 0, 3, 1, 4).reshape(3, x.size()[0]*kernel_size, x.size()[1]*kernel_size).permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zWPTXW9xlgK"
   },
   "source": [
    "### PatchCore\n",
    "1. Interpolate and match H, W with largest H, W. <br>\n",
    "2. Unfold and create patches <br>\n",
    "3. Adaptive average pool and create locally aware patch features <br>\n",
    "4. concatine features from different layers and adaptive average pool<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grkCq-Vk6za7",
    "outputId": "3d1f9884-8ebf-49aa-bce9-7584e8ba6972"
   },
   "outputs": [],
   "source": [
    "print(test_outputs[\"layer2\"].size())\n",
    "print(test_outputs[\"layer3\"].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXXRfnQ0x9yC",
    "outputId": "1fa8e608-b5d6-424a-da81-f2d8cb2cdb7d"
   },
   "outputs": [],
   "source": [
    "patched_agg_train = []\n",
    "patched_agg_test = []\n",
    "\n",
    "print(\"Here, the steps are\")\n",
    "print()\n",
    "print(\"1. H x W -> H_j x W_j 2D interpolation\")\n",
    "print(\"2. patchify\")\n",
    "print(\"3. 1D interpolation of C*k*k to pre-defined dim\")\n",
    "print(\"4. concatinate layers and 1D interpolation to predefined-dim\")\n",
    "print()\n",
    "print(\"but in the paper's repo they seem to do 2 and then 1.\")\n",
    "print()\n",
    "\n",
    "k = 3\n",
    "m = nn.AdaptiveAvgPool2d(train_outputs['layer2'].size()[2])\n",
    "\n",
    "\n",
    "for output, patched_agg in [(train_outputs, patched_agg_train), (test_outputs, patched_agg_test)]:\n",
    "  for layer in ['layer2', 'layer3']:\n",
    "    # print(\"---\")\n",
    "\n",
    "    # print(\"B x C x H x W\")\n",
    "    # print(list(output[layer].size()))\n",
    "    # print()\n",
    "\n",
    "    x = F.interpolate(output[layer],\n",
    "                size=(output['layer2'].size()[-2], output['layer2'].size()[-1]),\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False,\n",
    "            )\n",
    "\n",
    "    # print(\"B x C x H_j x W_j\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    # print(\"**interpolation H x W -> H_j x W_j completed**\")\n",
    "    # print()\n",
    "\n",
    "    # Pad to make output the same size\n",
    "    x = F.pad(x, (0, 0, k//2, k//2))\n",
    "\n",
    "    # print(\"k//2:\", k//2)\n",
    "    # print()\n",
    "\n",
    "    # print(\"B x C x (H_j + 2 * k//2) x W_j\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    x = x.unfold(2, k, step=1)\n",
    "\n",
    "    # print(\"B x C x H_j x W_j x k\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    x = F.pad(x, (0, 0, k//2, k//2, 0, 0))\n",
    "\n",
    "    # print(\"B x C x H_j x (W_j + 2 * k//2) x k\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    x = x.unfold(3, k, step=1)\n",
    "    # print(\"B x C x H_j x W_j x k x k\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    # print(\"**patch creation completed**\")\n",
    "    # print()\n",
    "\n",
    "    x = x.permute([0, 2, 3, 1, 4, 5])\n",
    "    # print(\"B x H_j x W_j x C x k x k\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    x = x.reshape(x.size()[0], -1, *x.size()[-3:])\n",
    "    # print(\"B x (H_j*W_j) x C x k x k\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    x = x.reshape(-1, *x.size()[-3:])\n",
    "    # print(\"(B*H_j*W_j) x C x k x k\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    x = x.reshape(len(x), 1, -1)\n",
    "    # print(\"(B*H_j*W_j) x 1 x (C*k*k)\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    x = (F.adaptive_avg_pool1d(x, 1024)).squeeze()\n",
    "    # print(\"(B*H_j*W_j) x 1024\")\n",
    "    # print(list(x.size()))\n",
    "    # print()\n",
    "\n",
    "    # print(\"**locally aware patch features created**\")\n",
    "    # print()\n",
    "    # Aggregate with adaptive average pool\n",
    "\n",
    "    patched_agg.append(x)\n",
    "\n",
    "# performing what is done in \"Aggregator\" class of paper\n",
    "memory_bank = F.adaptive_avg_pool1d(torch.cat(patched_agg_train, dim=-1), 1024)\n",
    "test_feats = F.adaptive_avg_pool1d(torch.cat(patched_agg_test, dim=-1), 1024).reshape(testset.__len__(), -1, 1024)\n",
    "\n",
    "print()\n",
    "print(\"memory bank M size:\")\n",
    "print(list(memory_bank.size()))\n",
    "print()\n",
    "\n",
    "print(\"-- steps 1-4 completed --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3lDn44XvtWI"
   },
   "source": [
    "### Coreset Sampling (k-center problem) <br>\n",
    "\"choose b center\n",
    "points such that the largest distance between a data\n",
    "point and its nearest center is minimized\"<br>\n",
    "ApproximateGreedyCoresetSampler in PatchCore Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCr833gGKg1L"
   },
   "outputs": [],
   "source": [
    "# based on PatchCore  github\n",
    "# Compute the distance between the row vectors of X and a single vector y.\n",
    "def matrix_rows_vs_vec_dist(X, y):\n",
    "\n",
    "    ### B x 1 x C  @ B x C x 1 (vec inner product) => B x 1 x 1\n",
    "    X_times_X = X.unsqueeze(1).bmm(X.unsqueeze(2)).reshape(-1, 1)\n",
    "    y_times_y = y.unsqueeze(1).bmm(y.unsqueeze(2)).reshape(-1, 1).permute(1, 0)\n",
    "    X_times_y = X.mm(y.T)\n",
    "\n",
    "    return X_times_X + y_times_y - 2  * X_times_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru9yJAEyCPSf"
   },
   "outputs": [],
   "source": [
    "# Greedy approximate algorithm for k-centers problem:\n",
    "def greedy_k_center(M, k):\n",
    "  centers = []\n",
    "  # Choose random center\n",
    "  cur_center = np.random.randint(len(M))\n",
    "  centers.append(cur_center)\n",
    "\n",
    "  # Distance bwtween all points in M and initial center\n",
    "  dist_to_closest_ctr = matrix_rows_vs_vec_dist(M, M[cur_center].unsqueeze(0))\n",
    "\n",
    "  for i in tqdm(range(k)):\n",
    "    # Find point farthest from current ind\n",
    "    new_center = torch.argmax(torch.squeeze(dist_to_closest_ctr))\n",
    "\n",
    "    # record new point\n",
    "    centers.append(new_center)\n",
    "\n",
    "    # compute distance between all points and y_new\n",
    "    dist_to_new_center = matrix_rows_vs_vec_dist(M, M[new_center].unsqueeze(0))\n",
    "\n",
    "    # dist to closest center in the list of centers\n",
    "    dist_to_closest_ctr = torch.min(torch.cat((dist_to_closest_ctr, dist_to_new_center), dim=-1), dim=-1).values.unsqueeze(1)\n",
    "\n",
    "  return centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfZKgqppZaaP",
    "outputId": "1758c3cb-caa2-4e39-aba0-41970ec62661"
   },
   "outputs": [],
   "source": [
    "# n: reduction factor\n",
    "n = 0.01\n",
    "\n",
    "with torch.no_grad():\n",
    "  # psi: Random Linear Projection\n",
    "\n",
    "  psi = torch.nn.Linear(memory_bank.size()[-1], 128, bias=False).cuda().eval()\n",
    "  M_proj = psi(memory_bank.cuda())\n",
    "\n",
    "  centers = greedy_k_center(M_proj, int(n * len(memory_bank)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1OWMsrcS1jJ",
    "outputId": "f4e17fb8-4de0-4a9b-9404-dc4f14a32b46"
   },
   "outputs": [],
   "source": [
    "Mc = memory_bank[centers]\n",
    "print(\"-- Memory bank coreset created --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PS137oJ68Zgb"
   },
   "source": [
    "### Check our greedy k-center algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "AuWTjrQ6YdRZ",
    "outputId": "f2c31b23-63bc-402c-a60f-6f289b8990eb"
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "points_2d = torch.from_numpy(np.concatenate((np.random.normal(loc=7, scale=4, size=(N, 2)), np.random.normal(loc=-5, scale=2, size=(N, 2)))))\n",
    "\n",
    "inds = torch.tensor(greedy_k_center(points_2d, 300))\n",
    "mask = np.full(2*N, True, dtype=bool)\n",
    "mask[inds] = False\n",
    "\n",
    "plt.scatter(points_2d[mask][:, 0], points_2d[mask][:, 1])\n",
    "plt.scatter(points_2d[inds][:, 0], points_2d[inds][:, 1], color=\"red\")\n",
    "plt.title(\"k-centers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2N1PuruHYFAj",
    "outputId": "92536e97-88e1-4d09-a4bb-f6edd309c177"
   },
   "outputs": [],
   "source": [
    "print(Mc.size())\n",
    "print(test_feats.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTCTeBih8hVI"
   },
   "source": [
    "### Create Score Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCIAKvUYYPQV",
    "outputId": "647ea366-36a0-4c68-bfd8-df50b39e3bd8"
   },
   "outputs": [],
   "source": [
    "score_map_list = []\n",
    "for i in range(len(test_feats)):\n",
    "  argmin_m = []\n",
    "  min_m = []\n",
    "  for y in tqdm(test_feats[i]):\n",
    "    X = Mc\n",
    "    y = y.unsqueeze(0)\n",
    "\n",
    "    min_m.append(torch.min(matrix_rows_vs_vec_dist(X, y)))\n",
    "    argmin_m.append(torch.argmin(matrix_rows_vs_vec_dist(X, y)))\n",
    "\n",
    "  m_test_star_ind = np.argmax(min_m)\n",
    "  m_star_ind = argmin_m[m_test_star_ind]\n",
    "\n",
    "  s_star = torch.sqrt(torch.sum((test_feats[i][m_test_star_ind] - Mc[m_star_ind])**2))\n",
    "\n",
    "  # b nearest patch features in Mc of test patch feature m_test_star_ind\n",
    "  m_test_vec = test_feats[i][m_test_star_ind].unsqueeze(0)\n",
    "\n",
    "  dist = matrix_rows_vs_vec_dist(Mc, m_test_vec)\n",
    "\n",
    "  top_b = torch.topk(torch.squeeze(dist), 5).indices\n",
    "  neighbor_vects = Mc[top_b]\n",
    "\n",
    "  numerator = torch.exp(s_star)\n",
    "  denominator = torch.sum(torch.exp(torch.sqrt(torch.sum((neighbor_vects - m_test_vec) ** 2, dim=-1))))\n",
    "\n",
    "  s = (1-numerator/denominator) * s_star\n",
    "\n",
    "  score_map = torch.reshape(torch.tensor(min_m), (28, 28))\n",
    "\n",
    "  score_map_list.append(score_map)\n",
    "\n",
    "\n",
    "map_interpolated = torch.zeros((len(score_map_list), 224, 224))\n",
    "for item in range(len(score_map_list)):\n",
    "    map_interpolated[item] = F.interpolate(score_map_list[item].unsqueeze(0).unsqueeze(0), size=224,mode='bilinear', align_corners=False)\n",
    "\n",
    "# for item in map_interpolated:\n",
    "#   plt.imshow(item, vmin=torch.min(map_interpolated), vmax=torch.max(map_interpolated))\n",
    "#   plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLzLPQr-wJHR"
   },
   "outputs": [],
   "source": [
    "def overlay_heatmap_on_image(img, heatmap, ratio_img=0.5):\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    heatmap = 1 - np.clip(heatmap, 0, 1)\n",
    "    heatmap = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    heatmap = heatmap.astype(np.float32)\n",
    "\n",
    "    overlay = (img * ratio_img) + (heatmap * (1 - ratio_img))\n",
    "    overlay = overlay.astype(np.uint8)\n",
    "    overlay = np.clip(overlay, 0, 255)\n",
    "    return overlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RBp8W5VGqPJk",
    "outputId": "c8a36729-dbc8-4b58-811b-f366fec2c63e"
   },
   "outputs": [],
   "source": [
    "for item in range(len(map_interpolated)):\n",
    "    print(\"---\")\n",
    "    if item < 3:\n",
    "      print(\"defect\")\n",
    "    else:\n",
    "      print(\"good\")\n",
    "    score_map_ = map_interpolated[item]\n",
    "\n",
    "    score_map_ = gaussian_filter(score_map_, sigma=4)\n",
    "\n",
    "    score_map_ = score_map_ - torch.min(map_interpolated).item()\n",
    "    score_map_ = score_map_ / torch.max(map_interpolated).item()\n",
    "\n",
    "    # threshold score map\n",
    "\n",
    "    col_preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    col_anomaly = col_preprocess(Image.open(test_paths[item])).permute(1, 2, 0).numpy() * 255\n",
    "\n",
    "    plt.imshow(np.clip(col_anomaly.astype(np.uint8), 0, 255))\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(overlay_heatmap_on_image(col_anomaly, score_map_, 0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UyIQu5L7xMQ"
   },
   "source": [
    "References: <br>\n",
    "https://tech.anytech.co.jp/entry/2023/03/24/100000 <br>\n",
    "https://github.com/amazon-science/patchcore-inspection/tree/b64be4734cb8295bfbadccf4f6a036b266181e57/src/patchcore <br>\n",
    "https://github.com/amazon-science/patchcore-inspection/issues/21#issuecomment-1148390290 <br>\n",
    "https://www.cs.umd.edu/class/fall2017/cmsc451-0101/Lects/lect08-greedy-k-center.pdf <br>\n",
    "https://github.com/amazon-science/patchcore-inspection/issues/4#issuecomment-1123763551"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
